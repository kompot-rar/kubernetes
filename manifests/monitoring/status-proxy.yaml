apiVersion: apps/v1
kind: Deployment
metadata:
  name: status-proxy
  namespace: monitoring
  labels:
    app: status-proxy
spec:
  replicas: 1
  selector:
    matchLabels:
      app: status-proxy
  template:
    metadata:
      labels:
        app: status-proxy
    spec:
      serviceAccountName: status-proxy-sa
      containers:
      - name: proxy
        image: node:18-alpine
        workingDir: /app
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: GITHUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: github-token
              key: token
        - name: ARGOCD_TOKEN
          valueFrom:
            secretKeyRef:
              name: argocd-token
              key: token
              optional: true
        - name: CF_API_TOKEN
          valueFrom:
            secretKeyRef:
              name: cf-token
              key: token
              optional: true
        - name: CF_ZONE_ID
          valueFrom:
            secretKeyRef:
              name: cf-token
              key: zone_id
              optional: true
        command: ["sh", "-c"]
        args:
        - |
          cd /app && \
          npm init -y && \
          npm install --production --no-package-lock --no-audit --no-fund express axios cors && \
          cat <<'EOF' > index.js
          const express = require('express');
          const axios = require('axios');
          const cors = require('cors');
          const https = require('https');
          const fs = require('fs');
          const app = express();
          app.use(cors());

          // Kubernetes internal client
          const K8S_URL = "https://kubernetes.default.svc";
          let k8sToken = "";
          try { k8sToken = fs.readFileSync('/var/run/secrets/kubernetes.io/serviceaccount/token', 'utf8'); } catch(e) {}
          const k8sClient = axios.create({
            baseURL: K8S_URL,
            httpsAgent: new https.Agent({ rejectUnauthorized: false }),
            headers: { "Authorization": `Bearer ${k8sToken}` }
          });

          const PROM_URL = "http://monitoring-kube-prometheus-prometheus.monitoring.svc:9090/api/v1/query";
          const GITHUB_REPO = "kompot-rar/Vibe_devops";
          const GITHUB_TOKEN = process.env.GITHUB_TOKEN;
          const ARGOCD_URL = "https://argocd-server.argocd.svc"; // Internal Cluster URL
          const ARGOCD_TOKEN = process.env.ARGOCD_TOKEN;
          
          // Cloudflare config
          const CF_API_TOKEN = process.env.CF_API_TOKEN;
          const CF_ZONE_ID = process.env.CF_ZONE_ID;

          const githubClient = axios.create({
            baseURL: "https://api.github.com",
            headers: {
              "Accept": "application/vnd.github.v3+json",
              ...(GITHUB_TOKEN && { "Authorization": `Bearer ${GITHUB_TOKEN}` })
            }
          });

          const argoClient = axios.create({
            baseURL: ARGOCD_URL,
            httpsAgent: new https.Agent({  
              rejectUnauthorized: false // Ignore self-signed certs internal to cluster
            }),
            headers: {
              ...(ARGOCD_TOKEN && { "Authorization": `Bearer ${ARGOCD_TOKEN}` })
            }
          });

          const queryProm = async (q) => {
            try {
              const res = await axios.get(PROM_URL, { params: { query: q }, timeout: 5000 });
              return res.data.data.result;
            } catch (e) {
              console.error(`Query Error (${q}):`, e.message);
              return [];
            }
          };

          const queryPromRange = async (q, start, end, step) => {
            try {
              const rangeUrl = PROM_URL.replace('/query', '/query_range');
              const res = await axios.get(rangeUrl, { 
                params: { query: q, start, end, step }, 
                timeout: 5000 
              });
              return res.data.data.result;
            } catch (e) {
              console.error(`Query Range Error (${q}):`, e.message);
              return [];
            }
          };

          const getArgoApps = async () => {
            try {
              if (!ARGOCD_TOKEN) return [];
              
              const res = await argoClient.get('/api/v1/applications');
              if (!res.data.items) return [];

              return res.data.items.map(app => ({
                name: app.metadata.name,
                status: app.status.health.status,
                sync: app.status.sync.status,
                revision: app.status.sync.revision ? app.status.sync.revision.substring(0, 7) : 'N/A',
                last_deploy: app.status.history && app.status.history.length > 0 
                  ? app.status.history[app.status.history.length - 1].deployedAt 
                  : 'Never',
                repo: app.spec.source.repoURL,
                path: app.spec.source.path
              }));
            } catch (e) {
              console.error("ArgoCD API Error:", e.message);
              return [];
            }
          };

          const getGitHubStatus = async () => {
            try {
              if (!GITHUB_TOKEN) return { run: null, jobs: [] };
              
              const runsRes = await githubClient.get(`/repos/${GITHUB_REPO}/actions/runs`, {
                params: { per_page: 1, branch: "main" }
              });
              
              if (!runsRes.data.workflow_runs || runsRes.data.workflow_runs.length === 0) {
                return { run: null, jobs: [] };
              }

              const latestRun = runsRes.data.workflow_runs[0];
              const jobsRes = await githubClient.get(latestRun.jobs_url);
              
              const runData = {
                id: latestRun.id,
                name: latestRun.name,
                status: latestRun.status,
                conclusion: latestRun.conclusion,
                head_sha: latestRun.head_sha,
                head_commit: {
                  message: latestRun.head_commit ? latestRun.head_commit.message : "No message",
                  author: { name: latestRun.head_commit ? latestRun.head_commit.author.name : "Unknown" },
                  timestamp: latestRun.head_commit ? latestRun.head_commit.timestamp : latestRun.created_at
                },
                created_at: latestRun.created_at,
                updated_at: latestRun.updated_at,
                html_url: latestRun.html_url
              };

              const jobsData = (jobsRes.data.jobs || []).map(job => ({
                id: job.id,
                name: job.name,
                status: job.status,
                conclusion: job.conclusion,
                html_url: job.html_url,
                steps: job.steps.map(step => ({
                  name: step.name,
                  number: step.number,
                  status: step.status,
                  conclusion: step.conclusion,
                  started_at: step.started_at,
                  completed_at: step.completed_at
                }))
              }));

              return { run: runData, jobs: jobsData };

            } catch (e) {
              console.error("GitHub API Error:", e.message);
              return { run: { status: "unknown", error: "Failed to fetch from GitHub" }, jobs: [] };
            }
          };

          const getDoraMetrics = async () => {
            try {
              if (!GITHUB_TOKEN) return null;
              
              const thirtyDaysAgo = new Date();
              thirtyDaysAgo.setDate(thirtyDaysAgo.getDate() - 30);
              const createdAfter = thirtyDaysAgo.toISOString();

              const runsRes = await githubClient.get(`/repos/${GITHUB_REPO}/actions/runs`, {
                params: { 
                  branch: "main", 
                  status: "completed", 
                  created: `>${createdAfter}`,
                  per_page: 100 
                }
              });

              const runs = runsRes.data.workflow_runs || [];
              if (runs.length === 0) return null;

              const deploys_30d = runs.length;
              const deployment_frequency_per_week = parseFloat((deploys_30d / 4.3).toFixed(2));
              
              const successfulRuns = runs.filter(r => r.conclusion === 'success');
              const leadTimes = successfulRuns.map(r => {
                const updatedAt = new Date(r.updated_at).getTime();
                const committedAt = new Date(r.head_commit ? r.head_commit.timestamp : r.created_at).getTime();
                return (updatedAt - committedAt) / (1000 * 60);
              });
              
              const lead_time_avg_minutes = leadTimes.length > 0 
                ? parseFloat((leadTimes.reduce((a, b) => a + b, 0) / leadTimes.length).toFixed(1))
                : 0;

              const failed_deploys_30d = runs.filter(r => r.conclusion === 'failure').length;
              const change_failure_rate_pct = deploys_30d > 0 
                ? parseFloat(((failed_deploys_30d / deploys_30d) * 100).toFixed(1))
                : 0;

              return {
                deployment_frequency_per_week,
                lead_time_avg_minutes,
                change_failure_rate_pct,
                deploys_30d,
                failed_deploys_30d
              };
            } catch (e) {
              console.error("DORA Metrics Error:", e.message);
              return null;
            }
          };

          const getCloudflareStats = async () => {
            if (!CF_API_TOKEN || !CF_ZONE_ID) return null;
            
            // Query for the last 7 days
            const d = new Date();
            d.setDate(d.getDate() - 7);
            const dateGt = d.toISOString().split('T')[0];

            const query = `
              query getZoneStats($zoneTag: String!, $dateGt: String!) {
                viewer {
                  zones(filter: { zoneTag: $zoneTag }) {
                    httpRequests1dGroups(limit: 7, filter: { date_gt: $dateGt }) {
                      sum {
                        requests
                        bytes
                        cachedBytes
                        threats
                        pageViews
                        countryMap {
                          requests
                          clientCountryName
                        }
                        responseStatusMap {
                          requests
                          edgeResponseStatus
                        }
                      }
                      uniq {
                        uniques
                      }
                    }
                  }
                }
              }
            `;

            try {
              const res = await axios.post('https://api.cloudflare.com/client/v4/graphql', {
                query,
                variables: { zoneTag: CF_ZONE_ID, dateGt: dateGt }
              }, {
                headers: {
                  'Authorization': `Bearer ${CF_API_TOKEN}`,
                  'Content-Type': 'application/json'
                }
              });

              if (res.data.errors) {
                console.error("Cloudflare GraphQL Error from API:", JSON.stringify(res.data.errors));
                return null;
              }

              const zones = res.data?.data?.viewer?.zones;
              if (!zones || zones.length === 0) return null;
              
              const groups = zones[0].httpRequests1dGroups;
              
              // Aggregate the 7 days data
              let totalRequests = 0;
              let totalThreats = 0;
              let totalBytes = 0;
              let cachedBytes = 0;
              let error5xx = 0;
              let uniqueVisitors = 0;
              const countryMap = {};

              groups.forEach(g => {
                totalRequests += g.sum.requests || 0;
                totalThreats += g.sum.threats || 0;
                totalBytes += g.sum.bytes || 0;
                cachedBytes += g.sum.cachedBytes || 0;
                uniqueVisitors += g.uniq.uniques || 0;

                (g.sum.responseStatusMap || []).forEach(s => {
                  if (s.edgeResponseStatus >= 500 && s.edgeResponseStatus < 600) {
                    error5xx += s.requests;
                  }
                });

                (g.sum.countryMap || []).forEach(c => {
                  countryMap[c.clientCountryName] = (countryMap[c.clientCountryName] || 0) + c.requests;
                });
              });

              // Top 3 countries
              const topCountries = Object.entries(countryMap)
                .sort((a, b) => b[1] - a[1])
                .slice(0, 3)
                .map(c => c[0]);

              const cacheRatio = totalBytes > 0 ? ((cachedBytes / totalBytes) * 100).toFixed(1) : "0.0";
              const errorRate = totalRequests > 0 ? ((error5xx / totalRequests) * 100).toFixed(2) : "0.00";
              const savedTransferGB = (cachedBytes / 1024 / 1024 / 1024).toFixed(2);

              return {
                security: {
                  threats_blocked: totalThreats
                },
                performance: {
                  cache_hit_ratio_pct: cacheRatio,
                  saved_transfer_gb: savedTransferGB
                },
                traffic: {
                  unique_visitors_7d: uniqueVisitors,
                  top_countries: topCountries
                },
                reliability: {
                  edge_error_rate_pct: errorRate,
                  synthetic_uptime_pct: (100 - parseFloat(errorRate)).toFixed(2)
                }
              };
            } catch (e) {
              console.error("Cloudflare GraphQL Error:", e.response ? JSON.stringify(e.response.data) : e.message);
              return null;
            }
          };

          const getRecentIncidents = async () => {
            try {
              if (!k8sToken) return [];
              const res = await k8sClient.get('/api/v1/events');
              if (!res.data.items) return [];

              const incidentReasons = ['Unhealthy', 'BackOff', 'Failed', 'Killing', 'Evicted', 'FailedScheduling'];
              
              return res.data.items
                .filter(e => incidentReasons.includes(e.reason) || e.type === 'Warning')
                .map(e => ({
                  type: e.type,
                  reason: e.reason,
                  message: e.message,
                  object: `${e.involvedObject.kind}/${e.involvedObject.name}`,
                  namespace: e.involvedObject.namespace,
                  count: e.count,
                  last_timestamp: e.lastTimestamp || e.eventTime || e.firstTimestamp
                }))
                .sort((a, b) => new Date(b.last_timestamp) - new Date(a.last_timestamp))
                .slice(0, 5);
            } catch (e) {
              console.error("K8s Events API Error:", e.message);
              return [];
            }
          };

          app.get('/api/status', async (req, res) => {
            try {
              const now = Math.floor(Date.now() / 1000);
              const thirtyDaysAgo = now - (30 * 24 * 60 * 60);

              const [
                promData,
                githubData,
                argoApps,
                cloudflareData,
                k8sNodesRes,
                k8sPodsRes,
                incidents,
                slaData,
                doraData
              ] = await Promise.all([
                Promise.all([
                  queryProm('max(node_hwmon_temp_celsius) by (instance)'),
                  queryProm('sum(kube_pod_status_phase{phase="Running"})'),
                  queryProm('100 * (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes))'),
                  queryProm('100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)'),
                  queryProm('time() - node_boot_time_seconds'),
                  queryProm('sum(increase(kube_pod_container_status_restarts_total[24h]))'),
                  queryProm('sum(kube_pod_status_phase{phase=~"Failed|Pending|Unknown"})'),
                  queryProm('count(argocd_app_info{sync_status="Synced"})'),
                  // Chaos Monkey
                  queryProm('smartmon_reallocated_sector_count_raw_value{instance="10.0.10.13:9100", disk="/dev/sda"}'),
                  queryProm('smartmon_offline_uncorrectable_raw_value{instance="10.0.10.13:9100", disk="/dev/sda"}'),
                  queryProm('smartmon_wear_leveling_count_raw_value{instance="10.0.10.13:9100", disk="/dev/sda"}'),
                  queryProm('rate(node_disk_write_time_seconds_total{instance="10.0.10.13:9100", device="sda"}[5m])'),
                  queryProm('smartmon_device_info{instance="10.0.10.13:9100", disk="/dev/sda"}'),
                  queryProm('smartmon_reallocated_event_count_raw_value{instance="10.0.10.13:9100", disk="/dev/sda"}'),
                  queryProm('smartmon_reported_uncorrect_raw_value{instance="10.0.10.13:9100", disk="/dev/sda"}'),
                  queryProm('smartmon_device_smart_healthy{instance="10.0.10.13:9100", disk="/dev/sda"}'),
                  queryProm('smartmon_percent_lifetime_remain_raw_value{instance="10.0.10.13:9100", disk="/dev/sda"}'),
                  queryProm('smartmon_power_on_hours_raw_value{instance="10.0.10.13:9100", disk="/dev/sda"}'),
                  // Cluster Stats (Pressure & Network)
                  queryProm('(sum(kube_pod_container_resource_requests{resource="cpu"}) / sum(kube_node_status_allocatable{resource="cpu"})) * 100'),
                  queryProm('(sum(kube_pod_container_resource_requests{resource="memory"}) / sum(kube_node_status_allocatable{resource="memory"})) * 100'),
                  queryProm('sum(rate(node_network_receive_bytes_total{device!="lo"}[2m]))'),
                  queryProm('sum(rate(node_network_transmit_bytes_total{device!="lo"}[2m]))')
                ]),
                getGitHubStatus(),
                getArgoApps(),
                getCloudflareStats(),
                k8sToken ? k8sClient.get('/api/v1/nodes').catch(() => ({ data: { items: [] } })) : Promise.resolve({ data: { items: [] } }),
                k8sToken ? k8sClient.get('/api/v1/pods').catch(() => ({ data: { items: [] } })) : Promise.resolve({ data: { items: [] } }),
                getRecentIncidents(),
                (async () => {
                  try {
                    return await Promise.all([
                      queryProm('sla:availability:30d'),
                      queryPromRange('sla:availability:daily', thirtyDaysAgo, now, '1d'),
                      queryProm('sla:downtime:minutes:30d'),
                      queryProm('sla:response_time:p95:30d'),
                      queryPromRange('sla:response_time:avg:daily', thirtyDaysAgo, now, '1d'),
                      // Uproszczony streak: jeśli nie było awarii, zwróć 720h (30 dni)
                      queryProm('min(time() - timestamp(probe_success{job="blackbox", instance="https://devops.mrozy.org"} == 0) / 3600) OR on() vector(720)')
                    ]);
                  } catch (e) {
                    console.error("SLA Data Fetch Error:", e.message);
                    return [[], [], [], [], [], []];
                  }
                })(),
                getDoraMetrics()
              ]);

              const [temp, pods, ram, cpu, uptime, restarts24h, unhealthyPods, argoSync, chaosSectors, chaosErrors, chaosWear, chaosWriteLat, chaosInfo, chaosEvents, chaosReportedUncorrect, chaosSmartHealthy, chaosLifeRemain, chaosPowerHours, cpuPressure, memPressure, netRx, netTx] = promData;
              const [uptime30d, dailyUptime, downtime30d, p95_30d, dailyLatency, streakData] = (slaData || [[], [], [], [], [], []]);

              const nodes = temp.map((t) => {
                const instance = t.metric.instance;
                const cpuVal = cpu.find(c => c.metric.instance === instance);
                const ramVal = ram.find(r => r.metric.instance === instance);
                const upVal = uptime.find(u => u.metric.instance === instance);
                
                return {
                  name: instance.split(':')[0],
                  temp: t.value ? parseFloat(t.value[1]).toFixed(1) : "0",
                  cpu: cpuVal ? parseFloat(cpuVal.value[1]).toFixed(1) : "0",
                  ram: ramVal ? parseFloat(ramVal.value[1]).toFixed(1) : "0",
                  uptime: upVal ? (parseFloat(upVal.value[1]) / 86400).toFixed(1) : "0"
                };
              });

              // Merge daily uptime and latency
              const dailyMapped = (dailyUptime && dailyUptime[0] && dailyUptime[0].values || []).map((v, i) => {
                const latVal = dailyLatency && dailyLatency[0] && dailyLatency[0].values && dailyLatency[0].values[i] ? dailyLatency[0].values[i][1] : 0;
                return {
                  date: new Date(v[0] * 1000).toISOString().split('T')[0],
                  uptime_pct: parseFloat((parseFloat(v[1]) * 100).toFixed(2)),
                  avg_response_ms: parseInt((parseFloat(latVal) * 1000).toFixed(0))
                };
              });

              // Chaos Monkey Logic
              const sectors = chaosSectors[0] ? parseInt(chaosSectors[0].value[1]) : 0;
              const errors = chaosErrors[0] ? parseInt(chaosErrors[0].value[1]) : 0;
              const wear = chaosWear[0] ? parseInt(chaosWear[0].value[1]) : 0;
              const writeLat = chaosWriteLat[0] ? parseFloat(chaosWriteLat[0].value[1]) : 0;
              const info = chaosInfo[0] ? chaosInfo[0].metric : {};
              const events = chaosEvents[0] ? parseInt(chaosEvents[0].value[1]) : 0;
              const reportedUncorrect = chaosReportedUncorrect[0] ? parseInt(chaosReportedUncorrect[0].value[1]) : 0;
              const isSmartHealthy = chaosSmartHealthy[0] ? parseInt(chaosSmartHealthy[0].value[1]) === 1 : false;
              const lifeRemain = chaosLifeRemain[0] ? parseInt(chaosLifeRemain[0].value[1]) : 100;
              const powerHours = chaosPowerHours[0] ? parseInt(chaosPowerHours[0].value[1]) : 0;

              let chaosStatus = "Stable (For a dumpster disk)";
              let chaosNote = "Running on salvaged hardware. No data is safe here.";
              
              if (reportedUncorrect > 1000) {
                chaosStatus = "Radioactive (ECC Failure)";
                chaosNote = "Massive hardware ECC errors. Bit-rot is actively occurring.";
              } else if (lifeRemain < 10) {
                chaosStatus = "EOL (End of Life)";
                chaosNote = "NAND cells exhausted. Write operations are high-risk.";
              } else if (errors > 0) {
                chaosStatus = "Dying (Data Loss Detected)";
                chaosNote = "Uncorrectable sectors found. SMART self-test is screaming.";
              } else if (writeLat > 0.5) {
                chaosStatus = "Throttling (Floppy Disk Mode)";
                chaosNote = "High write latency detected. Controller struggling with bad cells.";
              }

              const restartCount = restarts24h[0] ? Math.round(parseFloat(restarts24h[0].value[1])) : 0;
              const unhealthyCount = unhealthyPods[0] ? parseInt(unhealthyPods[0].value[1]) : 0;
              const isSynced = argoSync[0] ? parseInt(argoSync[0].value[1]) > 0 : false;
              
              let clusterStatus = "Healthy";
              let statusMessage = isSynced ? "GitOps Synced. All systems operational." : "Cluster Operational. Manual changes detected.";
              
              if (unhealthyCount > 0) {
                clusterStatus = "Warning";
                statusMessage = `Self-healing active: ${unhealthyCount} pod(s) recovering.`;
              }

              res.json({
                // SLA Fields at Top Level
                uptime_30d_pct: uptime30d[0] ? parseFloat((parseFloat(uptime30d[0].value[1]) * 100).toFixed(2)) : 0,
                current_streak_hours: streakData[0] ? parseFloat(parseFloat(streakData[0].value[1]).toFixed(1)) : 720.0,
                total_downtime_minutes_30d: downtime30d[0] ? parseFloat(parseFloat(downtime30d[0].value[1]).toFixed(1)) : 0,
                response_time_p95_ms: p95_30d[0] ? Math.round(parseFloat(p95_30d[0].value[1]) * 1000) : 0,
                daily: dailyMapped,

                cluster: {
                  totalPods: pods[0] ? pods[0].value[1] : "0",
                  status: clusterStatus,
                  message: statusMessage,
                  gitops: isSynced ? "Synced" : "Out of Sync",
                  lastUpdate: new Date().toISOString(),
                  restarts_24h: restartCount,
                  unhealthy_pods: unhealthyCount,
                  incidents: incidents,
                  stats: {
                    cpu_pressure: cpuPressure[0] ? parseFloat(cpuPressure[0].value[1]).toFixed(1) : "0",
                    memory_pressure: memPressure[0] ? parseFloat(memPressure[0].value[1]).toFixed(1) : "0",
                    network_rx_mbps: netRx[0] ? (parseFloat(netRx[0].value[1]) / 1024 / 1024 * 8).toFixed(2) : "0",
                    network_tx_mbps: netTx[0] ? (parseFloat(netTx[0].value[1]) / 1024 / 1024 * 8).toFixed(2) : "0"
                  }
                },
                incidents: incidents,
                chaos_monkey_audit: {
                  target: info.device_model || "Crucial_MX300 (Dumpster)",
                  serial: info.serial_number || "N/A",
                  node: "10.0.10.13",
                  health_status: chaosStatus,
                  firmware_verdict: isSmartHealthy ? "PASSED (Optimistic)" : "FAILED (Critical)",
                  alert_level: reportedUncorrect > 0 ? "Radioactive" : (lifeRemain < 30 ? "Critical" : (errors > 0 ? "Critical" : (sectors > 0 || events > 0 ? "Warning" : "Nominal"))),
                  metrics: {
                    reallocated_sectors: sectors,
                    reallocated_events: events,
                    offline_uncorrectable: errors,
                    reported_uncorrectable_ecc: reportedUncorrect,
                    ssd_wear_cycles: wear,
                    lifetime_remain_pct: lifeRemain,
                    power_on_hours: powerHours,
                    avg_write_lat_sec: writeLat.toFixed(4)
                  },
                  sre_message: chaosNote
                },
                cloudflare: cloudflareData || { message: "Cloudflare integration not configured or data unavailable." },
                nodes: nodes,
                run: githubData.run,
                jobs: githubData.jobs,
                dora: doraData,
                argocd_apps: argoApps,
                topology: {
                  nodes: (k8sNodesRes.data && k8sNodesRes.data.items ? k8sNodesRes.data.items : []).map(n => {
                    const nodeName = n.metadata.name;
                    return {
                      name: nodeName,
                      status: n.status && n.status.conditions ? (n.status.conditions.find(c => c.type === 'Ready') || {}).status || 'Unknown' : 'Unknown',
                      pods: (k8sPodsRes.data && k8sPodsRes.data.items ? k8sPodsRes.data.items : [])
                        .filter(p => p.spec.nodeName === nodeName)
                        .map(p => ({
                          name: p.metadata.name,
                          namespace: p.metadata.namespace,
                          status: p.status ? p.status.phase : 'Unknown'
                        }))
                    };
                  }),
                  whoami: {
                    pod: process.env.POD_NAME || 'status-proxy',
                    node: process.env.NODE_NAME || 'unknown'
                  }
                }
              });
            } catch (e) {
              res.status(502).json({ error: "Błąd serwera statusu", details: e.message });
            }
          });

          app.get('/api/status/logs/:jobId', async (req, res) => {
            const { jobId } = req.params;
            try {
              if (!GITHUB_TOKEN) {
                 return res.status(500).json({ error: "Missing GITHUB_TOKEN" });
              }

              const logsRes = await githubClient.get(`/repos/${GITHUB_REPO}/actions/jobs/${jobId}/logs`, {
                responseType: 'text'
              });

              // Process logs
              const rawLogs = logsRes.data;
              const allLines = rawLogs.split('\n');
              
              const cleanLines = allLines
                .filter(line => !line.includes('##[debug]'))
                .map(line => line.replace(/^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d+Z /, '')) // Remove ISO timestamp
                .slice(0, 1000); // Limit to 1000 lines

              res.json({ lines: cleanLines });

            } catch (e) {
              console.error(`Logs Error (${jobId}):`, e.message);
              res.status(502).json({ error: "Failed to fetch logs", details: e.message });
            }
          });

          // Dedicated endpoint for Argo Apps (optional usage)
          app.get('/api/argocd/apps', async (req, res) => {
             const apps = await getArgoApps();
             res.json(apps);
          });

          // Diagnostic endpoint for pod restarts
          app.get('/api/status/restart-reason/:podName', async (req, res) => {
            const { podName } = req.params;
            try {
              if (!k8sToken) return res.status(500).json({ error: "K8s Token missing" });

              // 1. Get Pod details to find namespace and termination state
              const allPodsRes = await k8sClient.get('/api/v1/pods');
              const pod = allPodsRes.data.items.find(p => p.metadata.name === podName);

              if (!pod) return res.status(404).json({ error: "Pod not found" });

              const namespace = pod.metadata.namespace;
              const containerStatuses = pod.status.containerStatuses || [];
              
              // We look for the first container that has a non-empty lastState.terminated
              const lastState = containerStatuses
                .map(c => c.lastState ? c.lastState.terminated : null)
                .find(t => t != null);

              // 2. Get specific events for this pod
              const eventsRes = await k8sClient.get(`/api/v1/namespaces/${namespace}/events`, {
                params: { fieldSelector: `involvedObject.name=${podName}` }
              });

              const recentEvents = (eventsRes.data.items || [])
                .map(e => ({
                  type: e.type,
                  reason: e.reason,
                  message: e.message,
                  count: e.count,
                  last_seen: e.lastTimestamp || e.eventTime || e.firstTimestamp
                }))
                .sort((a, b) => new Date(b.last_seen) - new Date(a.last_seen))
                .slice(0, 10);

              res.json({
                pod_name: podName,
                namespace: namespace,
                diagnostic: {
                  last_termination: lastState ? {
                    reason: lastState.reason,
                    exit_code: lastState.exitCode,
                    started_at: lastState.startedAt,
                    finished_at: lastState.finishedAt,
                    container_id: lastState.containerID
                  } : null,
                  recent_events: recentEvents
                }
              });

            } catch (e) {
              console.error(`Diagnostic Error (${podName}):`, e.message);
              res.status(502).json({ error: "Failed to fetch diagnostic data", details: e.message });
            }
          });

          app.get('/health', (req, res) => res.send('OK'));
          app.listen(3000, () => console.log('Super-Status Proxy v2.2 (24h Window) listening on port 3000'));
          EOF
          node index.js
        ports:
        - containerPort: 3000
        resources:
          requests:
            cpu: 20m
            memory: 64Mi
          limits:
            cpu: 200m
            memory: 512Mi
---
apiVersion: v1
kind: Service
metadata:
  name: status-proxy
  namespace: monitoring
spec:
  selector:
    app: status-proxy
  ports:
  - port: 80
    targetPort: 3000
